<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta name="color-scheme" content="light dark">

    

    <meta name="author" content="Daniel Parrales">
    <meta name="description" content="Cluster de Alta Disponibilidad">
    <meta name="keywords" content="blog,developer,personal,">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cluster de Alta Disponibilidad"/>
<meta name="twitter:description" content="Cluster de Alta Disponibilidad"/>

    <meta property="og:title" content="Cluster de Alta Disponibilidad" />
<meta property="og:description" content="Cluster de Alta Disponibilidad" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sysadblog.onrender.com/posts/practica_cluster_alta_disponibilidad/" />
<meta property="article:published_time" content="2022-02-17T14:29:07+01:00" />
<meta property="article:modified_time" content="2022-02-17T14:29:07+01:00" />


    <title>
  Cluster de Alta Disponibilidad · Sysadblog
</title>

    
      <link rel="canonical" href="https://sysadblog.onrender.com/posts/practica_cluster_alta_disponibilidad/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.8e2b2510f60e1715eae08d113a808dcdaf17f6f711edb9e969be38d0074d240d.css" integrity="sha256-jislEPYOFxXq4I0ROoCNza8X9vcR7bnpab440AdNJA0=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.aa883b9ce35a8ff4a2a5008619005175e842bb18a8a9f9cc2bbcf44dab2d91fa.css" integrity="sha256-qog7nONaj/SipQCGGQBRdehCuxioqfnMK7z0Tastkfo=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    

    <meta name="generator" content="Hugo 0.80.0" />
  </head>

  
  
    
  
  <body class="preload-transitions colorscheme-auto"
        onload=""
  >
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Sysadblog
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/aboutme">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/categories">Categories</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://sysadblog.onrender.com/posts/practica_cluster_alta_disponibilidad/">
              Cluster de Alta Disponibilidad
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime='2022-02-17T14:29:07&#43;01:00'>
                February 17, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              8-minute read
            </span>
          </div>
          <div class="authors">
    <i class="fa fa-user" aria-hidden="true"></i>
      <a href="/authors/daniel-parrales/">Daniel Parrales</a></div>
          <div class="categories">
  <i class="fa fa-folder" aria-hidden="true"></i>
    <a href="/categories/seguridad-y-alta-disponibilidad/">Seguridad y Alta Disponibilidad</a></div>

          
        </div>
      </header>

      <div>
        
        <h1 id="cluster-de-alta-disponibilidad">
  Cluster de Alta Disponibilidad
  <a class="heading-link" href="#cluster-de-alta-disponibilidad">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>El objetivo de este práctica es la instalación de una aplicación php (WordPress) sobe dos cluster de alta disponibilidad:</p>
<h2 id="cluster-de-ha-activo-pasivo">
  Cluster de HA activo-pasivo
  <a class="heading-link" href="#cluster-de-ha-activo-pasivo">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<ol>
<li>Utiliza el <code>Vagrantfile</code> la receta ansible del escenario 6: <a href="https://github.com/josedom24/escenarios-HA/tree/master/06-HA-IPFailover-Apache2+DRBD+GFS2">06-HA-IPFailover-Apache2+DRBD+GFS2</a> para crear un cluster de alta disponibilidad activo-pasivo. Nota: La receta instala apache2 + php.</li>
<li>Comprueba que los recursos están configurados de manera adecuada, configura tu host para que use el servidor DNS y comprueba que puedes acceder de forma adecuada a la página.</li>
<li>Instala en los dos nodos un Galera MariaDB.</li>
<li>Instala Wordpress en el cluster.</li>
</ol>
<hr>
<p>Tras haber levantado el escenario y pasado la receta de ansible, podemos ver que ha configurado el cluster y se han activado los servicios:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_1.png" alt="img_1.png"></p>
<p>Ahora comprobemos que ambos nodos muestran la página de forma correcta. Para ello, cambiamos la configuración de nuestro anfitrión para que use de servidor dns el &ldquo;nodo dns&rdquo; y accedemos a la página:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_2.png" alt="img_2.png"></p>
<p>Si apagamos el nodo1, debería poderse seguir visualizando la página en el nodo 2:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_3.png" alt="img_3.png"></p>
<p>A continuación, para tener la base de datos que va a utilizar Wordpress en alta disponibilidad, vamos a instalar Galera MariaDB en ambos nodos. Para ello, en primer lugar, debemos instalar mariadb en ambos nodos:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">apt install mariadb-server
</code></pre></div><p>También es aconsejable ejecutar el script para securizar mariadb:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">mysql_secure_installation
</code></pre></div><p>Después, hay que elegir un nodo en el que instalaremos el cluster. En mi caso, he elegido el nodo 1. En primer lugar, detenemos el servicio de mariadb:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">systemctl stop mariadb.service
</code></pre></div><p>Después hemos de modificar el fichero de configuración del cluster Galera (<code>/etc/mysql/mariadb.conf.d/60-galera.cnf</code>):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">nano /etc/mysql/mariadb.conf.d/60-galera.cnf

[galera]
wsrep_on                 = 1
wsrep_cluster_name       = &#34;MariaDB Galera Cluster&#34;
wsrep_provider           = /usr/lib/galera/libgalera_smm.so
wsrep_cluster_address    = gcomm://10.1.1.101,10.1.1.102
binlog_format            = row
default_storage_engine   = InnoDB
innodb_autoinc_lock_mode = 2

# Allow server to accept connections on all interfaces.
bind-address = 0.0.0.0
wsrep_node_address=10.1.1.101
</code></pre></div><p>Podemos señalar algunos parámetros importantes:</p>
<ul>
<li><strong>wsrep_on = 1:</strong> Activa el cluster.</li>
<li><strong>wsrep_cluster_address:</strong> Indicamos las IP de los nodos que van a formar parte del cluster.</li>
<li><strong>bind-address = 0.0.0.0:</strong> Permitimos las conexiones a la base de datos desde todas las interfaces de red.</li>
<li><strong>wsrep_node_address:</strong> Dirección IP del nodo que estamos configurando.</li>
</ul>
<p>A continuación, creamos el cluster e iniciamos el servicio:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">galera_new_cluster

systemctl start mariadb.service 
</code></pre></div><p>Podemos comprobar que se ha creado correctamente si entramos en la base de datos y ejecutamos lo siguiente (todo lo que comienza por <code>wsrep_</code> hace referencia al cluster):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">MariaDB [(none)]&gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 1     |
+--------------------+-------+
1 row in set (0.001 sec)
</code></pre></div><p>Como vemos, nos indica que el cluster Galera solo tiene un miembro. Ahora añadamos al nodo 2 al cluster. Para ello, en el nodo2, añadimos la misma configuración de antes pero cambiando la ip del nodo2:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">[galera]
wsrep_on                 = 1
wsrep_cluster_name       = &#34;MariaDB Galera Cluster&#34;
wsrep_provider           = /usr/lib/galera/libgalera_smm.so
wsrep_cluster_address    = gcomm://10.1.1.101,10.1.1.102
binlog_format            = row
default_storage_engine   = InnoDB
innodb_autoinc_lock_mode = 2

# Allow server to accept connections on all interfaces.
bind-address = 0.0.0.0
wsrep_node_address=10.1.1.102
</code></pre></div><p>Y reiniciamos el servicio en el nodo2:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">systemctl restart mariadb
</code></pre></div><p>Ahora, si ejecutamos lo mismo que antes, nos debería indicar que hay dos nodos en el cluster de Galera:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_4.png" alt="img_4.png"></p>
<p>Con el cluster de Galera instalado y funcionando, pasamos a crear la base de datos que usará wordpress:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_5.png" alt="img_5.png"></p>
<p>Ahora nos descargamos e instalamos wordpress en el nodo1 (ya que en este momento es el nodo activo):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">cd /var/www/html

wget https://es.wordpress.org/latest-es_ES.tar.gz

tar -xf latest-es_ES.tar.gz

rm latest-es_ES.tar.gz

chown -R www-data: wordpress/
</code></pre></div><p>Ahora, entramos en la url y terminamos de instalar wordpress. Una vez hecho esto, entramos en la zona de administración y creamos una entrada que contenga una imagen:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_6.png" alt="img_6.png"></p>
<p>Ahora, si apagamos el nodo1, todos los recursos deberían pasar al nodo2, ya que se encuentra en alta disponibilidad, por lo que la imagen y el post debería poder seguir viéndose:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_7.png" alt="img_7.png"></p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_8.png" alt="img_8.png"></p>
<p>Con esto, podemos dar por finalizada esta parte de la tarea.</p>
<hr>
<h2 id="cluster-de-ha-activo-activo">
  Cluster de HA activo-activo
  <a class="heading-link" href="#cluster-de-ha-activo-activo">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>Siguiendo las instrucciones que encuentras en el escenario 6: <a href="https://github.com/josedom24/escenarios-HA/tree/master/06-HA-IPFailover-Apache2+DRBD+GFS2">06-HA-IPFailover-Apache2+DRBD+GFS2</a> convierte el cluster en activo-activo. Es necesario instalar el <a href="https://github.com/josedom24/escenarios-HA/blob/master/06-HA-IPFailover-Apache2%2BDRBD%2BGFS2/fencing.md">fencing</a> para que el cluster funcione de manera adecuada. Nota: Tienes que tener en cuenta que se va a formatear de nuevo el drbd, por lo que se va a perder el wordpress. Si quieres puedes guardarlo en otro directorio, para luego recuperarlo.</p>
<p>Una vez que el cluster este configurado como activo-activo y WordPress esté funcionado, deberá configurarse un método de balanceo de carga.</p>
<hr>
<p>En primer lugar, debemos instalar en ambos nodos &ldquo;GFS2&rdquo; y el programa DLM, que será el encargado de gestionar el acceso del cluster al almacenamiento distribuido:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">apt install gfs2-utils dlm-controld
</code></pre></div><p>El DLM debe ejecutarse en los dos nodos, por lo que debemos crear un recurso &ldquo;ocf:pacemaker:controld&rdquo;:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs cluster cib dlm_cfg
pcs -f dlm_cfg resource create dlm ocf:pacemaker:controld op monitor interval=60s
pcs -f dlm_cfg resource clone dlm clone-max=2 clone-node-max=1
pcs cluster cib-push dlm_cfg --config
</code></pre></div><p>Tras esto, podemos ver que se ha creado el recurso:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_9.png" alt="img_9.png"></p>
<p>Ahora debemos crear el sistema de archivos &ldquo;GFS2&rdquo;, para lo cual debemos deshabilitar primero el recurso que controlaba el sistema de archivos anterior:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs resource disable WebFS
</code></pre></div><p>Comprobamos que se ha detenido:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_10.png" alt="img_10.png"></p>
<p>Ya podemos formatear el dispositivo de bloques:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">mkfs.gfs2 -p lock_dlm -j 2 -t mycluster:web /dev/drbd1
</code></pre></div><p>Donde:</p>
<ul>
<li><strong>-p lock_dlm:</strong> Indica que vamos a usar el programa DLM (Distributed Lock Manager) para gestionar los cambiso del sistema de archivo.</li>
<li><strong>-j 2:</strong> Se va a reservar espacio para 2 journals (registro donde se almacena información necesaria para recuperar los datos afectados por una transición en caso de que falle) uno para cada nodo.</li>
<li><strong>-t mycluster:web:</strong> El nombre de la tabla de bloqueo (lock) (<code>web</code>) en el cluster <code>mycluster</code> (nombre del cluster que indicamos al crearlo con corosync y que lo podemos encontrar en <code>/etc/corosync/corosync.conf</code>).</li>
</ul>
<p>Ya podemos guardar información en el dispositivo de bloques:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">mount /dev/drbd1 /mnt
cd /mnt/
echo &#34;&lt;h1&gt;Prueba con GFS2&lt;/h1&gt;&#34; &gt;&gt; index.html
umount /mnt
</code></pre></div><p>Una vez que hemos hecho esto, debemos reconfigurar el recurso del cluster &ldquo;WebFS&rdquo; con el nuevo tipo de sistema de fichero:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs resource update WebFS fstype=gfs2
</code></pre></div><p>GFS2 necesita que DLM este funcionando, por lo que tenemos que poner dos restricciones:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs constraint colocation add WebFS with dlm-clone INFINITY
pcs constraint order dlm-clone then WebFS
</code></pre></div><p>Por último. debemos montar el recurso del sistema de ficheros <em>WebFS</em> en los dos nodos y modificar el recurso <em>WebData-clone</em> para indicar que ambos se pongan como primarios en el DRBD:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs cluster cib active_cfg
pcs -f active_cfg resource clone WebFS
pcs -f active_cfg constraint
pcs -f active_cfg resource update WebData-clone promoted-max=2
pcs cluster cib-push active_cfg --config
pcs resource enable WebFS
</code></pre></div><p>Podemos comprobar que los recursos se encuentran activados en los dos nodos, y que ambos nodos son <em>Masters</em>:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_11.png" alt="img_11.png"></p>
<p>Cualquiera de los servidores web pueden escribir ficheros en <code>/var/www/html</code>, por lo que podemos clonar el recurso <em>WebSite</em> y quitar la restricción de colocación que hacía que el servidor web se activa en el nodo que tenía asignada la VirtualIP:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs cluster cib active_cfg
pcs -f active_cfg resource clone WebSite
pcs cluster cib-push active_cfg --config
pcs constraint colocation delete WebSite-clone VirtualIP
</code></pre></div><p>Comprobamos:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_12.png" alt="img_12.png"></p>
<p>Ahora debemos configurar el &ldquo;Fencing&rdquo; y &ldquo;STONITH&rdquo;. Podemos ver los agentes que podemos usar ejecutando lo siguiente:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs stonith list
</code></pre></div><p>Como nosotros estamos haciendo uso de máquina &ldquo;KVM&rdquo;, haremos uso del agente <code>external/libvirt</code>. Para ello, primero debemos instalarlo en ambos nodos:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">apt install libvirt-clients
</code></pre></div><p>Ambos nodos deben ser capaces de acceder al host por ssh con el usuario &ldquo;root&rdquo; sin contraseña. Para ello nos generaremos en ambos nodos un par de claves y las añadiremos al host:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">ssh-keygen -t rsa
ssh-copy-id 192.168.121.1
</code></pre></div><p>Debemos comprobar que parámetros necesitamos configurar en el stonith con este agente. Para ello, ejecutamos lo siguiente:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs stonith describe external/libvirt
</code></pre></div><p>Y vemos que tenemos que indicar al menos dos parámetros obligatoriamente:</p>
<ul>
<li><strong>hostlist:</strong> Una lista que relaciona los hostnames de los nodos del cluster con el nombre de la máquina virtual en el hypervisor. En nuestro caso el valor sería:</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">hostlist=&#34;nodo1:06-HA-IPFailover-Apache2DRBDGFS2_nodo1,nodo2:06-HA-IPFailover-Apache2DRBDGFS2_nodo2&#34;
</code></pre></div><ul>
<li><strong>hypervisor_uri:</strong> La uri del sistema de virtualización KVM. En nuestro caso:</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">qemu+ssh://192.168.121.1/system
</code></pre></div><p>Con estos datos, podemos habilitar en fencing en el cluster:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">pcs cluster cib stonith_cfg
pcs -f stonith_cfg stonith create fencing-libvirt external/libvirt \
 hostlist=&#34;nodo1:06-HA-IPFailover-Apache2DRBDGFS2_nodo1,nodo2:06-HA-IPFailover-Apache2DRBDGFS2_nodo2&#34; \
 hypervisor_uri=&#34;qemu+ssh://192.168.121.1/system&#34;
pcs -f stonith_cfg property set stonith-enabled=true
pcs cluster cib-push stonith_cfg --config
</code></pre></div><p><img src="/images/practica_cluster_alta_disponibilidad/img_13.png" alt="img_13.png"></p>
<p>Una vez hecho esto, debemos volver a instalar wordpress, ya que al haber formateado el dispositivo de bloques se ha perdido la información. La instalación de wordpress sigue los mismos pasos que antes. Una vez que hemos configurado la base de datos nos indica que wordpress ya se encuentra instalado (debido a que la información sigue guardada en la base de datos), por lo que podemos acceder con las credenciales antiguas. La imagen que subimos si se perdió, ya que no estaba guardada en la base de datos. Así pues, he vuelto a subir la misma imagen, recuperando el post anterior:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_14.png" alt="img_14.png"></p>
<p>A continuación, instalamos en el nodo &ldquo;dns&rdquo; HAproxy para balancear la carga:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">apt install haproxy
</code></pre></div><p>Y añadimos la siguiente configuración:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">nano /etc/haproxy/haproxy.cfg

frontend servidores_web
        bind *:80
        mode http
        stats enable
        stats uri /ha_stats
        stats auth  cda:cda
        default_backend servidores_web_backend

backend servidores_web_backend
        mode http
        balance roundrobin
        server backend1 10.1.1.101:80 check
        server backend2 10.1.1.102:80 check
</code></pre></div><p>También debemos modificar las zonas dns para que apunten a la nueva ip (la del nodo dns):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">nano /var/cache/bind/db.10.1.1

103                     PTR     www.example.com.

nano /var/cache/bind/db.example.com

www             A       10.1.1.103
</code></pre></div><p>Y reiniciamos el dns:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">systemctl restart bind9
</code></pre></div><p>Ahora, si accedemos a la página, la carga se estará balanceando entre los dos nodos aunque no nos demos cuenta:</p>
<p><img src="/images/practica_cluster_alta_disponibilidad/img_15.png" alt="img_15.png"></p>
<p>Con esto, damos por finalizada la práctica.</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
        <p>Para más entradas interesantes vean el blog de [Lara](https://sysraider.es)</p>
      
      
        ©
        
          2021 -
        
        2022
         Daniel Parrales 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
    </section>
  </footer>


    </main>

    
      
      <script src="/js/coder.min.a350362441276ec5c1671926420497bb8e52b63ead1d51d3c9bc4342d0039526.js" integrity="sha256-o1A2JEEnbsXBZxkmQgSXu45Stj6tHVHTybxDQtADlSY="></script>
    

    

    

    

    

    

    

    

    
  </body>

</html>
